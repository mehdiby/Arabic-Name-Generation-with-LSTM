{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM7hReATwJL6"
      },
      "source": [
        "#**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IpLuciaSwFQt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pickle\n",
        "from keras.models import load_model\n",
        "from pickle import load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIBNI1kwS2u"
      },
      "source": [
        "#**Data preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-IJDVJCyUp8"
      },
      "source": [
        "This code performs data loading and preprocessing for a text file containing names. It divides the names into sequences of length 3 and creates a mapping of unique characters to integers. By changing the input data file, you can generate a corresponding model for the new dataset by rerunning the code cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECvRFdvOwf12",
        "outputId": "673eaac5-1ddf-4374-bcad-66449d7bc711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿آلاء آمال آمنة آيات\n",
            "آية أبرار أثيل أحلام\n",
            "أروى أريج  أزهار أسارير\n",
            "أسماء أسمى أسيل أشجان\n",
            "أطياف أغاريد أفراح أفكار\n",
            "أفنان ألطاف ألوف أم كلثوم\n",
            "أمارة أمال أمامة أماميان\n",
            "أمانة أماني أمرات أملة\n",
            "أمنية أمورة أمونة أمية\n",
            "أميرة أميمة أميمية أمينة\n",
            "أمينة أناة أنار أنارات\n",
            "أنسام أنسة أنسوقة أنشودة\n",
            "أنصار أنظارأنظام أنغم\n",
            "أنوار أنوس أنوف أنيسة \n",
            "أنيسة أهداف أوبية أودة\n",
            "أوسال أوصاف أوصال أولياء\n",
            "أوها إباء إجلالإحسان\n",
            "إخلاص إدراك إسراء إسعاد\n",
            "إسعاف إشراف إصلاح إعزاز \n",
            "إقبال إقدام إكليل إمداد\n",
            "إمهال إناس إنجاح إنشاد\n",
            "إنصاف إنعام إهداف إهلال \n",
            "إيتاء إيثار إيحاء إيداع\n",
            "إيضاح إيفاء إيماء إيمان\n",
            "إيناس ابتسام ابتهاج ابتهال\n",
            "اجتهاد احتشام ازدهاراعتدال\n",
            "اعتماد افتخار افتكار الحد\n",
            "الحدة الدرداء السعدية السكينة\n",
            "النعيمة امتثال امتيازانبساط \n",
            "انبهاج انتصارانتظار انتهاء\n",
            "انجرار انسجام انشراح انشراف \n",
            "انشقار انفصال بائقة بادرة \n",
            "بارزة بارعة باركة بارية\n",
            "بازعة باسة باسطة باسقة\n",
            "باسلة بتول بثينة بحرية\n",
            "براء بسمة بسيمة بشرى \n",
            "بشيرة بلقيس بليغة بهيجة\n",
            "بهيسة بيبي تانيا تغاني\n",
            "تمارة تماضر تنال تودد\n",
            "تيسير تيماء تيمة ثراء \n",
            "ثوابة ثوبة ثويبة جبرة \n",
            "جبلة جمانة جميلة جميلة\n",
            "جيداء حجاب حدة حدية\n",
            "حسنية حفصة حليمة حليمة\n",
            "حنيفة حوارحورحوراء\n",
            "حورية حياة خزامى خولة\n",
            "داليا دانا دانية دعجاء\n",
            "دنيا ذبيانة ذكية راتبة\n",
            "راجحة راسخة راغبة رافقة \n",
            "رافية راقية رامة رانيا \n",
            "رباعي ربعة ربى رجب \n",
            "رجيحة رحاب رخاء رداح\n",
            "ردينة رزان رزينة رسمية\n",
            "رشا رشيقة رصينة رضا\n",
            "رضوة رغد رفيدة رفيعة\n",
            "رفيف رقية رقية رنا\n",
            "رنيم رهام  رهيفة رولا\n",
            "ريا رياض ريتا ريحانة\n",
            "ريم ريما زبيدة زبيدة \n",
            "زكية زهرة زهور زيانة\n",
            "زينب سؤدد سارة سالي \n",
            "سامية  ساندرا ساهدة  ساهرة \n",
            "سبيعة سجى سحر سدر \n",
            "سعاد سعدة سعيدة سعيدة  \n",
            "سفيانة سكين سكينة سلامة\n",
            "سلطانة سلمى سلوى سمة\n",
            "سمر سمراء سمية سميحة \n",
            "سميرة سناء سندس سنيحة\n",
            "سهاد سهى سهيلة سونيا\n",
            "سيارة شارد شاكرة شاهدة \n",
            "شاهرة شريفة شكرية شهلاء\n",
            "شيماء صائنة صابرة صبا\n",
            "صريحة صفا صفاء صفية \n",
            "ضارعة ضياء طامحة طريفة \n",
            "ظافرة ظعينة عائذة عائشة\n",
            "عابدة عاطفة عايدة عبادة\n",
            "عبلة عبير عتابة عزيزة\n",
            "عشير عفاف علجية علياء\n",
            "عنبر غادة غريبة غلا\n",
            "غناء غيد غيداء فائقة\n",
            "فاتن فادية فاطمة فتيحة \n",
            "فخرية فرح فردوس فريدة\n",
            "فصيحة فضل فكرية فلوة\n",
            "فنن فهيمة فوزية فيروز\n",
            "فيضية قطام قنوت كاتيا\n",
            "كارينا كاظمة كاملة كبرى\n",
            "كريمة كفى كنزى لؤلؤة\n",
            "لارا لانا لبانة لجينة\n",
            "لذة لطفية لطيفة لمى\n",
            "لميس لهيفة لوزت لولوه\n",
            "ليال ليلى لينا مارسيل\n",
            "ماهة ماهرة مبروكة متام\n",
            "مثابة مجاهدة مجيبة مجيدة\n",
            "مخلصة مدركة مديدة مرح\n",
            "مرحب مرهفة مروة مروى \n",
            "مريم مزينة مساعدة مسفرة \n",
            "مصلحة مطاعة مطيعة معطوب\n",
            "معطية معينة مغيثة مقبلة\n",
            "ملاك ملاكة ملهمة مليكة \n",
            "ممدوحة مناحة مناصف منذرة \n",
            "منصفة منى منيبة منيرة\n",
            "مها مهيبة ميا ميادة \n",
            "ميرا ميساء ميسون ميليسا\n",
            "ميمونة مينا ناتاشا ناجحة \n",
            "ناجدة نادية نادية نادين \n",
            "ناشئة ناصحة ناهية نبيلة \n",
            "نبيهة نجلاء نجوانة نجيبة\n",
            "نجيحة نداء ندرة ندى\n",
            "نزيهة نسرين نسيم نسيم \n",
            "نصاحة نصر نضال نظيرة \n",
            "نعيم نهال نهى نوار\n",
            "نوال نوال نورا نورة\n",
            "نورس نورهان هائلة هاجر\n",
            "هالة هانئة هدى  هديل \n",
            "هريرة هند هيفاء وداد\n",
            "وديعة ورد وسام وسيمة\n",
            "وفاء وفيقة ولهانة وليفة \n",
            "وميض وهبة يارا ياسمين يسرا \n",
            "Total Sequences: 2681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-d74f71ce9e37>:38: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "def load_doc(filename):\n",
        "    with open(filename, 'r', encoding=\"utf8\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "# tokenization, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "    data = '\\n'.join(lines)\n",
        "    with open(filename, 'w', encoding=\"utf8\") as file:\n",
        "        file.write(data)\n",
        "\n",
        "\n",
        "raw_text = load_doc('names.txt')\n",
        "print(raw_text)\n",
        "\n",
        "# start preprocess\n",
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n",
        "\n",
        "# devide into seq\n",
        "seq_len = 3\n",
        "step = 1\n",
        "sequences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(raw_text) - seq_len, step):\n",
        "    sequences.append(raw_text[i:i + seq_len])\n",
        "    next_chars.append(raw_text[i + seq_len])\n",
        "print('Total Sequences:', len(sequences))\n",
        "\n",
        "# create a mapping of unique characters to integers , in other words dict with an int for each charcter\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# create input and output pairs encoded as integers\n",
        "X = np.zeros((len(sequences), seq_len), dtype=np.int32)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "for i, seq in enumerate(sequences):\n",
        "    for j, char in enumerate(seq):\n",
        "        X[i, j] = char_to_int[char]\n",
        "    y[i, char_to_int[next_chars[i]]] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA9w8VaAwo5Z"
      },
      "source": [
        "# **Modelization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWTJgefiw8VH",
        "outputId": "2a1dc99b-c0e2-4569-fad4-e8e8ac4efd08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 3, 128)            4864      \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 256)               394240    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 38)                9766      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 408,870\n",
            "Trainable params: 408,870\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 3s 40ms/step - loss: 3.5100 - accuracy: 0.1731\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 2.9895 - accuracy: 0.1984\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 1s 66ms/step - loss: 2.7910 - accuracy: 0.2380\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 1s 65ms/step - loss: 2.6305 - accuracy: 0.2674\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 1s 41ms/step - loss: 2.5210 - accuracy: 0.2965\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.4414 - accuracy: 0.3100\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 1s 39ms/step - loss: 2.3836 - accuracy: 0.3238\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.3193 - accuracy: 0.3450\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 2.2722 - accuracy: 0.3558\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 2.2369 - accuracy: 0.3603\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 2.2118 - accuracy: 0.3637\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 2.1879 - accuracy: 0.3685\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 2.1723 - accuracy: 0.3655\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.1541 - accuracy: 0.3749\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 1s 39ms/step - loss: 2.1342 - accuracy: 0.3760\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 1s 40ms/step - loss: 2.1168 - accuracy: 0.3782\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 2.0998 - accuracy: 0.3939\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 1s 62ms/step - loss: 2.0731 - accuracy: 0.3924\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 1s 61ms/step - loss: 2.0499 - accuracy: 0.3924\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 1s 40ms/step - loss: 2.0347 - accuracy: 0.3969\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.0125 - accuracy: 0.3972\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.9911 - accuracy: 0.4054\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.9700 - accuracy: 0.4125\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.9512 - accuracy: 0.4159\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.9267 - accuracy: 0.4204\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 1s 43ms/step - loss: 1.9061 - accuracy: 0.4189\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 1.8817 - accuracy: 0.4293\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.8569 - accuracy: 0.4357\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.8448 - accuracy: 0.4372\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.8168 - accuracy: 0.4342\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.7966 - accuracy: 0.4431\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.7784 - accuracy: 0.4502\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 1s 62ms/step - loss: 1.7409 - accuracy: 0.4618\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 1s 61ms/step - loss: 1.7171 - accuracy: 0.4685\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 1s 39ms/step - loss: 1.6941 - accuracy: 0.4648\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.6666 - accuracy: 0.4786\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.6386 - accuracy: 0.4827\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.6124 - accuracy: 0.4912\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.5847 - accuracy: 0.4950\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.5596 - accuracy: 0.4950\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.5336 - accuracy: 0.5062\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.5009 - accuracy: 0.5159\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.4789 - accuracy: 0.5248\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.4488 - accuracy: 0.5308\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.4253 - accuracy: 0.5375\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 1s 40ms/step - loss: 1.4020 - accuracy: 0.5438\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 1s 44ms/step - loss: 1.3728 - accuracy: 0.5449\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 1s 61ms/step - loss: 1.3430 - accuracy: 0.5621\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 1s 61ms/step - loss: 1.3180 - accuracy: 0.5651\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 1s 43ms/step - loss: 1.2966 - accuracy: 0.5759\n"
          ]
        }
      ],
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(chars), 128, input_length=seq_len))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "print(model.summary())\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# define early stopping callback\n",
        "early_stop = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=50, batch_size=128, callbacks=[early_stop])\n",
        "\n",
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "with open('mapping.pkl', 'wb') as file:\n",
        "    pickle.dump(char_to_int, file)\n",
        "    pickle.dump(int_to_char, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzKlK8-9xERV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cT5F9FHrGv2"
      },
      "source": [
        "#**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ggW7pSrCsW",
        "outputId": "14dbf866-b77b-447f-f1e4-3678ec7ed544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "أوسام\n",
            "نبيهة \n",
            "مثابة\n"
          ]
        }
      ],
      "source": [
        "def generate_seq(model,  seed_text, num_chars):\n",
        "    seq_len=len(seed_text)\n",
        "    generated = seed_text\n",
        "    for i in range(num_chars):\n",
        "        # encode the characters as integers\n",
        "        x_pred = np.zeros((1, seq_len), dtype=np.int32)\n",
        "        for j, char in enumerate(seed_text):\n",
        "            x_pred[0, j] = char_to_int[char]\n",
        "        # predict character\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = np.argmax(preds)\n",
        "        next_char = int_to_char[next_index]\n",
        "        # append to input\n",
        "        generated += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "    return generated\n",
        "\n",
        "# load the model\n",
        "model = load_model('model.h5')\n",
        "# load the mapping\n",
        "mapping = load(open('mapping.pkl', 'rb'))\n",
        "print(generate_seq(model, 'أوس', 2)) # should print 'أوسام'\n",
        "print(generate_seq(model, 'نبي', 3)) # should print 'نبيهة'\n",
        "print(generate_seq(model, 'مثا', 2)) # should print 'مثابة'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yFlrAHyxESI"
      },
      "source": [
        "# **Full code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txv7gFMSop38",
        "outputId": "5d274cc0-073e-4709-dc3a-53cf59e977b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿آلاء آمال آمنة آيات\n",
            "آية أبرار أثيل أحلام\n",
            "أروى أريج  أزهار أسارير\n",
            "أسماء أسمى أسيل أشجان\n",
            "أطياف أغاريد أفراح أفكار\n",
            "أفنان ألطاف ألوف أم كلثوم\n",
            "أمارة أمال أمامة أماميان\n",
            "أمانة أماني أمرات أملة\n",
            "أمنية أمورة أمونة أمية\n",
            "أميرة أميمة أميمية أمينة\n",
            "أمينة أناة أنار أنارات\n",
            "أنسام أنسة أنسوقة أنشودة\n",
            "أنصار أنظارأنظام أنغم\n",
            "أنوار أنوس أنوف أنيسة \n",
            "أنيسة أهداف أوبية أودة\n",
            "أوسال أوصاف أوصال أولياء\n",
            "أوها إباء إجلالإحسان\n",
            "إخلاص إدراك إسراء إسعاد\n",
            "إسعاف إشراف إصلاح إعزاز \n",
            "إقبال إقدام إكليل إمداد\n",
            "إمهال إناس إنجاح إنشاد\n",
            "إنصاف إنعام إهداف إهلال \n",
            "إيتاء إيثار إيحاء إيداع\n",
            "إيضاح إيفاء إيماء إيمان\n",
            "إيناس ابتسام ابتهاج ابتهال\n",
            "اجتهاد احتشام ازدهاراعتدال\n",
            "اعتماد افتخار افتكار الحد\n",
            "الحدة الدرداء السعدية السكينة\n",
            "النعيمة امتثال امتيازانبساط \n",
            "انبهاج انتصارانتظار انتهاء\n",
            "انجرار انسجام انشراح انشراف \n",
            "انشقار انفصال بائقة بادرة \n",
            "بارزة بارعة باركة بارية\n",
            "بازعة باسة باسطة باسقة\n",
            "باسلة بتول بثينة بحرية\n",
            "براء بسمة بسيمة بشرى \n",
            "بشيرة بلقيس بليغة بهيجة\n",
            "بهيسة بيبي تانيا تغاني\n",
            "تمارة تماضر تنال تودد\n",
            "تيسير تيماء تيمة ثراء \n",
            "ثوابة ثوبة ثويبة جبرة \n",
            "جبلة جمانة جميلة جميلة\n",
            "جيداء حجاب حدة حدية\n",
            "حسنية حفصة حليمة حليمة\n",
            "حنيفة حوارحورحوراء\n",
            "حورية حياة خزامى خولة\n",
            "داليا دانا دانية دعجاء\n",
            "دنيا ذبيانة ذكية راتبة\n",
            "راجحة راسخة راغبة رافقة \n",
            "رافية راقية رامة رانيا \n",
            "رباعي ربعة ربى رجب \n",
            "رجيحة رحاب رخاء رداح\n",
            "ردينة رزان رزينة رسمية\n",
            "رشا رشيقة رصينة رضا\n",
            "رضوة رغد رفيدة رفيعة\n",
            "رفيف رقية رقية رنا\n",
            "رنيم رهام  رهيفة رولا\n",
            "ريا رياض ريتا ريحانة\n",
            "ريم ريما زبيدة زبيدة \n",
            "زكية زهرة زهور زيانة\n",
            "زينب سؤدد سارة سالي \n",
            "سامية  ساندرا ساهدة  ساهرة \n",
            "سبيعة سجى سحر سدر \n",
            "سعاد سعدة سعيدة سعيدة  \n",
            "سفيانة سكين سكينة سلامة\n",
            "سلطانة سلمى سلوى سمة\n",
            "سمر سمراء سمية سميحة \n",
            "سميرة سناء سندس سنيحة\n",
            "سهاد سهى سهيلة سونيا\n",
            "سيارة شارد شاكرة شاهدة \n",
            "شاهرة شريفة شكرية شهلاء\n",
            "شيماء صائنة صابرة صبا\n",
            "صريحة صفا صفاء صفية \n",
            "ضارعة ضياء طامحة طريفة \n",
            "ظافرة ظعينة عائذة عائشة\n",
            "عابدة عاطفة عايدة عبادة\n",
            "عبلة عبير عتابة عزيزة\n",
            "عشير عفاف علجية علياء\n",
            "عنبر غادة غريبة غلا\n",
            "غناء غيد غيداء فائقة\n",
            "فاتن فادية فاطمة فتيحة \n",
            "فخرية فرح فردوس فريدة\n",
            "فصيحة فضل فكرية فلوة\n",
            "فنن فهيمة فوزية فيروز\n",
            "فيضية قطام قنوت كاتيا\n",
            "كارينا كاظمة كاملة كبرى\n",
            "كريمة كفى كنزى لؤلؤة\n",
            "لارا لانا لبانة لجينة\n",
            "لذة لطفية لطيفة لمى\n",
            "لميس لهيفة لوزت لولوه\n",
            "ليال ليلى لينا مارسيل\n",
            "ماهة ماهرة مبروكة متام\n",
            "مثابة مجاهدة مجيبة مجيدة\n",
            "مخلصة مدركة مديدة مرح\n",
            "مرحب مرهفة مروة مروى \n",
            "مريم مزينة مساعدة مسفرة \n",
            "مصلحة مطاعة مطيعة معطوب\n",
            "معطية معينة مغيثة مقبلة\n",
            "ملاك ملاكة ملهمة مليكة \n",
            "ممدوحة مناحة مناصف منذرة \n",
            "منصفة منى منيبة منيرة\n",
            "مها مهيبة ميا ميادة \n",
            "ميرا ميساء ميسون ميليسا\n",
            "ميمونة مينا ناتاشا ناجحة \n",
            "ناجدة نادية نادية نادين \n",
            "ناشئة ناصحة ناهية نبيلة \n",
            "نبيهة نجلاء نجوانة نجيبة\n",
            "نجيحة نداء ندرة ندى\n",
            "نزيهة نسرين نسيم نسيم \n",
            "نصاحة نصر نضال نظيرة \n",
            "نعيم نهال نهى نوار\n",
            "نوال نوال نورا نورة\n",
            "نورس نورهان هائلة هاجر\n",
            "هالة هانئة هدى  هديل \n",
            "هريرة هند هيفاء وداد\n",
            "وديعة ورد وسام وسيمة\n",
            "وفاء وفيقة ولهانة وليفة \n",
            "وميض وهبة يارا ياسمين يسرا \n",
            "Total Sequences: 2681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-1ad464bb2139>:48: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 3, 128)            4864      \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 256)               394240    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 38)                9766      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 408,870\n",
            "Trainable params: 408,870\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 3s 35ms/step - loss: 3.5115 - accuracy: 0.1858\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 2.9970 - accuracy: 0.2010\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.7802 - accuracy: 0.2465\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.6276 - accuracy: 0.2753\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.5295 - accuracy: 0.2906\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 2.4542 - accuracy: 0.3182\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 1s 40ms/step - loss: 2.3994 - accuracy: 0.3234\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 1s 61ms/step - loss: 2.3535 - accuracy: 0.3387\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 1s 60ms/step - loss: 2.3063 - accuracy: 0.3543\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 2.2637 - accuracy: 0.3543\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.2275 - accuracy: 0.3607\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 2.2030 - accuracy: 0.3700\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 2.1837 - accuracy: 0.3711\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 2.1583 - accuracy: 0.3722\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.1473 - accuracy: 0.3752\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 2.1214 - accuracy: 0.3808\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.1035 - accuracy: 0.3808\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 1s 39ms/step - loss: 2.0837 - accuracy: 0.3860\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 2.0720 - accuracy: 0.3831\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.0519 - accuracy: 0.3935\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 2.0291 - accuracy: 0.3976\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 2.0076 - accuracy: 0.3954\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.9826 - accuracy: 0.4103\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 1s 61ms/step - loss: 1.9601 - accuracy: 0.4129\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.9430 - accuracy: 0.4148\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.9240 - accuracy: 0.4159\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.9111 - accuracy: 0.4174\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.8835 - accuracy: 0.4230\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 1s 38ms/step - loss: 1.8513 - accuracy: 0.4405\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.8351 - accuracy: 0.4424\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.8090 - accuracy: 0.4439\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 1s 34ms/step - loss: 1.7912 - accuracy: 0.4454\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.7633 - accuracy: 0.4510\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.7409 - accuracy: 0.4547\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.7063 - accuracy: 0.4711\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 1.6825 - accuracy: 0.4651\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.6574 - accuracy: 0.4786\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 1s 43ms/step - loss: 1.6349 - accuracy: 0.4883\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 1s 60ms/step - loss: 1.6041 - accuracy: 0.4886\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 1s 64ms/step - loss: 1.5722 - accuracy: 0.5017\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 1s 42ms/step - loss: 1.5520 - accuracy: 0.4991\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.5147 - accuracy: 0.5155\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.4901 - accuracy: 0.5259\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.4628 - accuracy: 0.5356\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.4343 - accuracy: 0.5423\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.4056 - accuracy: 0.5438\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 1.3819 - accuracy: 0.5509\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.3484 - accuracy: 0.5640\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.3278 - accuracy: 0.5666\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 1.3064 - accuracy: 0.5666\n",
            "أوسام\n",
            "نبيلة \n",
            "مثابة\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pickle\n",
        "from keras.models import load_model\n",
        "from pickle import load\n",
        "\n",
        "\n",
        "# load data\n",
        "def load_doc(filename):\n",
        "    with open(filename, 'r', encoding=\"utf8\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "# tokenization, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "    data = '\\n'.join(lines)\n",
        "    with open(filename, 'w', encoding=\"utf8\") as file:\n",
        "        file.write(data)\n",
        "\n",
        "\n",
        "raw_text = load_doc('names.txt')\n",
        "print(raw_text)\n",
        "\n",
        "# start preprocess\n",
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n",
        "\n",
        "# devide into seq\n",
        "seq_len = 3\n",
        "step = 1\n",
        "sequences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(raw_text) - seq_len, step):\n",
        "    sequences.append(raw_text[i:i + seq_len])\n",
        "    next_chars.append(raw_text[i + seq_len])\n",
        "print('Total Sequences:', len(sequences))\n",
        "\n",
        "# create a mapping of unique characters to integers , in other words dict with an int for each charcter\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# create input and output pairs encoded as integers\n",
        "X = np.zeros((len(sequences), seq_len), dtype=np.int32)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "for i, seq in enumerate(sequences):\n",
        "    for j, char in enumerate(seq):\n",
        "        X[i, j] = char_to_int[char]\n",
        "    y[i, char_to_int[next_chars[i]]] = 1\n",
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(chars), 128, input_length=seq_len))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "print(model.summary())\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# define early stopping callback\n",
        "early_stop = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=50, batch_size=128, callbacks=[early_stop])\n",
        "\n",
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the mapping\n",
        "with open('mapping.pkl', 'wb') as file:\n",
        "    pickle.dump(char_to_int, file)\n",
        "    pickle.dump(int_to_char, file)\n",
        "\n",
        "# generate a sequence of characters with a trained model\n",
        "def generate_seq(model,  seed_text, num_chars):\n",
        "    seq_len=len(seed_text)\n",
        "    generated = seed_text\n",
        "    for i in range(num_chars):\n",
        "        # encode the characters as integers\n",
        "        x_pred = np.zeros((1, seq_len), dtype=np.int32)\n",
        "        for j, char in enumerate(seed_text):\n",
        "            x_pred[0, j] = char_to_int[char]\n",
        "        # predict character\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = np.argmax(preds)\n",
        "        next_char = int_to_char[next_index]\n",
        "        # append to input\n",
        "        generated += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "    return generated\n",
        "\n",
        "# load the model\n",
        "model = load_model('model.h5')\n",
        "# load the mapping\n",
        "mapping = load(open('mapping.pkl', 'rb'))\n",
        "\n",
        "print(generate_seq(model, 'أوس', 2)) # should print 'أوسام'\n",
        "print(generate_seq(model, 'نبي', 3)) # should print 'نبيهة'\n",
        "print(generate_seq(model, 'مثا', 2)) # should print 'مثابة'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSgsSt-WSY1f",
        "outputId": "707106a6-399e-433a-d8bc-fd1bd0875a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV-noH0E1D3w",
        "outputId": "ceb8f02f-81cb-43b0-d62a-8a760e8eb5d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-05-04T18:19:38+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To acces the Gloable link please click https://a1aa-34-74-167-201.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [04/May/2023 18:21:22] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/May/2023 18:21:23] \"GET /static/style.css HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/May/2023 18:21:23] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/May/2023 18:22:00] \"POST /generate_names HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/May/2023 18:22:00] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/May/2023 18:22:08] \"POST /generate_names HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/May/2023 18:22:08] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/May/2023 18:22:14] \"POST /generate_names HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/May/2023 18:22:15] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pyngrok import ngrok\n",
        "from flask import url_for\n",
        "\n",
        "\n",
        "\n",
        "app = Flask(__name__,static_url_path='/static')\n",
        "ngrok.set_auth_token(\"type your token here\")\n",
        "public_url =  ngrok.connect(5000).public_url\n",
        "# load the model and character mapping\n",
        "model = model = load_model('model.h5')\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    css_url = url_for('static', filename='style.css')\n",
        "    return render_template('index.html',css_url=css_url)\n",
        "\n",
        "@app.route('/generate_names', methods=['POST'])\n",
        "def generate_names():\n",
        "    css_url = url_for('static', filename='style.css')\n",
        "    n_chars = 3\n",
        "    seed_text = request.form['seed_text']\n",
        "    num_names = 1\n",
        "    generated_names = []\n",
        "    for _ in range(num_names):\n",
        "        generated = generate_seq(model, seed_text, n_chars)\n",
        "        generated_names.append(generated)\n",
        "    \n",
        "    return render_template('index.html', names=generated_names,css_url=css_url)\n",
        "\n",
        "\n",
        "def generate_seq(model, seed_text, num_chars):\n",
        "    seq_len = len(seed_text)\n",
        "    generated = seed_text\n",
        "    for i in range(num_chars):\n",
        "        x_pred = np.zeros((1, seq_len), dtype=np.int32)\n",
        "        for j, char in enumerate(seed_text):\n",
        "            x_pred[0, j] = char_to_int[char]\n",
        "        \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = np.argmax(preds)\n",
        "        next_char = int_to_char[next_index]\n",
        "        \n",
        "        generated += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "    \n",
        "    return generated\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(f\"To acces the Gloable link please click {public_url}\")\n",
        "    app.run(debug=False)\n",
        "    # Connect your local port (5000) to a public URL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YENnlZ916rtx"
      },
      "outputs": [],
      "source": [
        "!pip install ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RuZSH936wj2"
      },
      "outputs": [],
      "source": [
        "!ngrok http 5000"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}